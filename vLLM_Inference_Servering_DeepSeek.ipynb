{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying DeepSeek-LLM-7B-Chat using vLLM\n",
    "\n",
    "vLLM is an open-source library designed to deliver high throughput and low latency for large language model (LLM) inference. It optimizes text generation workloads by efficiently batching requests and making full use of GPU resources, empowering developers to manage complex tasks like code generation and large-scale conversational AI.\n",
    "\n",
    "This tutorial guides you through setting up and running vLLM on AMD Instinctâ„¢ GPUs using the ROCm software stack. Learn how to configure your environment, containerize your workflow, and send test queries to the vLLM-supported inference server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the LLM using vLLM\n",
    "\n",
    "Start deploying the LLM (deepseek-ai/deepseek-llm-7b-chat) using vLLM in the Jupyter notebook:\n",
    "\n",
    "### Start the vLLM server \n",
    "\n",
    "Open a new tab in this Jypyter server, click on the terminal icon to open a new terminal, then copy the following command to launch the vLLM server:\n",
    "\n",
    "```bash\n",
    "HIP_VISIBLE_DEVICES=0 vllm serve /home/user/Models/deepseek-ai/deepseek-llm-7b-chat \\\n",
    "        --gpu-memory-utilization 0.9 \\\n",
    "        --swap-space 16 \\\n",
    "        --disable-log-requests \\\n",
    "        --dtype float16 \\\n",
    "        --max-model-len 2048 \\\n",
    "        --tensor-parallel-size 1 \\\n",
    "        --host 0.0.0.0 \\\n",
    "        --port 3000 \\\n",
    "        --num-scheduler-steps 10 \\\n",
    "        --max-num-seqs 128 \\\n",
    "        --max-num-batched-tokens 2048 \\\n",
    "        --max-model-len 2048 \\\n",
    "        --distributed-executor-backend \"mp\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully connecting, it displays `INFO:     Application startup complete.`.\n",
    "\n",
    "**Note**: In a multi-GPU environment, the setting `HIP_VISIBLE_DEVICES=x` is recommended to deploy the LLM on your preferred GPU.\n",
    "\n",
    "### Start the client\n",
    "\n",
    "After successfully running the server, as described above, run the following code to start your client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-3ba8e0bf51524fffa686d7b67c4e9b6b', 'object': 'chat.completion', 'created': 1751455990, 'model': '/home/user/Models/deepseek-ai/deepseek-llm-7b-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'reasoning_content': None, 'content': 'An AI agent is a software program that learns and interacts with its environment to achieve specific goals or tasks. It is designed to make decisions and take actions based on the information it receives from the environment, and it uses machine learning algorithms to improve its performance over time. AI agents can be used in a variety of applications, such as game playing, robotics, natural language processing, and virtual assistants. They can be classified into two categories: reactive agents, which only respond to the current state of the environment, and learning agents, which use machine learning algorithms to learn from experience and improve their performance over time.', 'tool_calls': []}, 'logprobs': None, 'finish_reason': 'stop', 'stop_reason': None}], 'usage': {'prompt_tokens': 36, 'total_tokens': 158, 'completion_tokens': 122, 'prompt_tokens_details': None}, 'prompt_logprobs': None, 'kv_transfer_params': None}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:3000/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"model\": \"/home/user/Models/deepseek-ai/deepseek-llm-7b-chat\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in the field of AI. Make sure to provide an explanation in few sentences.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the concept of AI Agents.\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"max_tokens\": 128\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Remember to match the Docker `--port` **3000** and the port indicated in the URL, for instance, http://localhost:**3000**. If the port is already used by another application, you can modify the number. \n",
    "\n",
    "##### If the connection is successful, the output will be:\n",
    "\n",
    "``` bash\n",
    "{'id': 'chatcmpl-3ba8e0bf51524fffa686d7b67c4e9b6b', 'object': 'chat.completion', 'created': 1751455990, 'model': '/home/user/Models/deepseek-ai/deepseek-llm-7b-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'reasoning_content': None, 'content': 'An AI agent is a software program that learns and interacts with its environment to achieve specific goals or tasks. It is designed to make decisions and take actions based on the information it receives from the environment, and it uses machine learning algorithms to improve its performance over time. AI agents can be used in a variety of applications, such as game playing, robotics, natural language processing, and virtual assistants...}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
